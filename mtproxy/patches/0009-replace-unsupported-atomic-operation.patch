diff --git a/common/mp-queue.c b/common/mp-queue.c
index de69bd4..320dce7 100644
--- a/common/mp-queue.c
+++ b/common/mp-queue.c
@@ -25,6 +25,8 @@
 #include <errno.h>
 #include <pthread.h>
 #include <signal.h>
+#include <stdatomic.h>
+#include <stdbool.h>
 #include <stddef.h>
 #include <stdio.h>
 #include <stdlib.h>
@@ -42,6 +44,10 @@
 #include "jobs/jobs.h"
 #include "common/common-stats.h"
 
+inline bool __sync_bool_compare_and_swap_8 (long long *ptr, long long oldval, long long newval) {
+  return atomic_compare_exchange_weak(ptr, &oldval, newval);
+}
+
 volatile int mpq_blocks_allocated, mpq_blocks_allocated_max, mpq_blocks_allocations, mpq_blocks_true_allocations, mpq_blocks_wasted, mpq_blocks_prepared;
 volatile int mpq_small_blocks_allocated, mpq_small_blocks_allocated_max;
 
@@ -110,7 +116,7 @@ int get_this_thread_id (void) {
   if (i) {
     return i;
   }
-  i = __sync_fetch_and_add (&mpq_threads, 1) + 1;
+  i = atomic_fetch_add (&mpq_threads, 1) + 1;
   assert (i > 0 && i < MAX_MPQ_THREADS);
   thread_hazard_pointers = mqb_hazard_ptr[i];
   return mpq_this_thread_id = i;
@@ -119,7 +125,7 @@ int get_this_thread_id (void) {
 /* custom semaphore implementation using futexes */
 
 int mp_sem_post (mp_sem_t *sem) {
-  __sync_fetch_and_add (&sem->value, 1);
+  atomic_fetch_add (&sem->value, 1);
   if (sem->waiting > 0) {
     syscall (__NR_futex, &sem->value, FUTEX_WAKE, 1, NULL, 0, 0);
   }
@@ -130,20 +136,20 @@ int mp_sem_wait (mp_sem_t *sem) {
   int v = sem->value, q = 0;
   while (1) {
     if (v > 0) {
-      v = __sync_fetch_and_add (&sem->value, -1);
+      v = atomic_fetch_add (&sem->value, -1);
       if (v > 0) {
 	return 0;
       }
-      v = __sync_add_and_fetch (&sem->value, 1);
+      v = atomic_fetch_add (&sem->value, 1) + 1;
     } else {
       if (v < 0 && q++ < 10) {
 	barrier ();
 	v = sem->value;
 	continue;
       }
-      __sync_fetch_and_add (&sem->waiting, 1);
+      atomic_fetch_add (&sem->waiting, 1);
       syscall (__NR_futex, &sem->value, FUTEX_WAIT, v, NULL, 0, 0);
-      __sync_fetch_and_add (&sem->waiting, -1);
+      atomic_fetch_add (&sem->waiting, -1);
       v = sem->value;
       q = 0;
     }
@@ -153,11 +159,11 @@ int mp_sem_wait (mp_sem_t *sem) {
 int mp_sem_trywait (mp_sem_t *sem) {
   int v = sem->value;
   if (v > 0) {
-    v = __sync_fetch_and_add (&sem->value, -1);
+    v = atomic_fetch_add (&sem->value, -1);
     if (v > 0) {
       return 0;
     }
-    __sync_fetch_and_add (&sem->value, 1);
+    atomic_fetch_add (&sem->value, 1);
   }
   return -1;
 }
@@ -175,7 +181,7 @@ struct mp_queue_block *alloc_mpq_block (mqn_value_t first_val, int allow_recursi
       if (!is_hazard_ptr (QB, 0, 2)) {
 	// reclaiming garbage
 	assert (QB->mqb_magic == MQ_BLOCK_GARBAGE_MAGIC); 
-	__sync_fetch_and_add (&mpq_blocks_wasted, -1);
+	atomic_fetch_add (&mpq_blocks_wasted, -1);
 	align_bytes = QB->mqb_align_bytes;
       } else {
 	mpq_push (is_small ? &MqGarbageSmallBlocks : &MqGarbageBlocks, QB, MPQF_RECURSIVE);
@@ -187,7 +193,7 @@ struct mp_queue_block *alloc_mpq_block (mqn_value_t first_val, int allow_recursi
       if (QB) {
 	assert (QB->mqb_magic == MQ_BLOCK_PREPARED_MAGIC); 
 	prepared = 1;
-	__sync_fetch_and_add (&mpq_blocks_prepared, -1);
+	atomic_fetch_add (&mpq_blocks_prepared, -1);
 	align_bytes = QB->mqb_align_bytes;
       }
     }
@@ -199,14 +205,14 @@ struct mp_queue_block *alloc_mpq_block (mqn_value_t first_val, int allow_recursi
     align_bytes = -(int)(long) new_block & (MPQ_BLOCK_ALIGNMENT - 1);
     QB = (struct mp_queue_block *) (new_block + align_bytes);
 
-    __sync_fetch_and_add (&mpq_blocks_true_allocations, 1);
+    atomic_fetch_add (&mpq_blocks_true_allocations, 1);
     if (is_small) {
-      int t = __sync_fetch_and_add (&mpq_small_blocks_allocated, 1);
+      int t = atomic_fetch_add (&mpq_small_blocks_allocated, 1);
       if (t >= mpq_small_blocks_allocated_max) {
 	__sync_bool_compare_and_swap (&mpq_small_blocks_allocated_max, mpq_small_blocks_allocated_max, t + 1);
       }
     } else {
-      int t = __sync_fetch_and_add (&mpq_blocks_allocated, 1);
+      int t = atomic_fetch_add (&mpq_blocks_allocated, 1);
       if (t >= mpq_blocks_allocated_max) {
 	__sync_bool_compare_and_swap (&mpq_blocks_allocated_max, mpq_blocks_allocated_max, t + 1);
       }
@@ -214,7 +220,7 @@ struct mp_queue_block *alloc_mpq_block (mqn_value_t first_val, int allow_recursi
   } else {
     assert (QB->mqb_size == size);
   }
-  __sync_fetch_and_add (&mpq_blocks_allocations, 1);
+  atomic_fetch_add (&mpq_blocks_allocations, 1);
 
   memset (QB, 0, offsetof (struct mp_queue_block, mqb_nodes));
   QB->mqb_align_bytes = align_bytes;
@@ -244,10 +250,10 @@ void free_mpq_block (struct mp_queue_block *QB) {
   assert ((unsigned) QB->mqb_align_bytes < MPQ_BLOCK_ALIGNMENT && !(QB->mqb_align_bytes & (sizeof (void *) - 1)));
   QB->mqb_magic = MQ_BLOCK_FREE_MAGIC;
   if (QB->mqb_size == MPQ_SMALL_BLOCK_SIZE) {
-    __sync_fetch_and_add (&mpq_small_blocks_allocated, -1);
+    atomic_fetch_add (&mpq_small_blocks_allocated, -1);
   } else {
     assert (QB->mqb_size == MPQ_BLOCK_SIZE);
-    __sync_fetch_and_add (&mpq_blocks_allocated, -1);
+    atomic_fetch_add (&mpq_blocks_allocated, -1);
   }
   free ((char *) QB - QB->mqb_align_bytes);
 }
@@ -278,7 +284,7 @@ mqn_value_t mpq_block_pop (struct mp_queue_block *QB) {
   // fprintf (stderr, "%d:mpq_block_pop(%p)\n", mpq_this_thread_id, QB);
   long size = QB->mqb_size;
   while (1) {
-    long h = __sync_fetch_and_add (&QB->mqb_head, 1);
+    long h = atomic_fetch_add (&QB->mqb_head, 1);
     // fprintf (stderr, "%d:  mpq_block_pop(%ld)\n", mpq_this_thread_id, h);
     mpq_node_t *node = &QB->mqb_nodes[h & (size - 1)];
     while (1) {
@@ -334,7 +340,7 @@ long mpq_block_push (struct mp_queue_block *QB, mqn_value_t val) {
   long size = QB->mqb_size;
   // fprintf (stderr, "%d:mpq_block_push(%p)\n", mpq_this_thread_id, QB);
   while (1) {
-    long t = __sync_fetch_and_add (&QB->mqb_tail, 1);
+    long t = atomic_fetch_add (&QB->mqb_tail, 1);
     // fprintf (stderr, "%d:  mpq_block_push(%ld)\n", mpq_this_thread_id, t);
     if (t & MQN_SAFE) {
       return -1L; // bad luck
@@ -361,7 +367,7 @@ long mpq_block_push (struct mp_queue_block *QB, mqn_value_t val) {
     long h = QB->mqb_head;
     barrier ();
     if (t - h >= size || ++iterations > 10) {
-      __sync_fetch_and_or (&QB->mqb_tail, MQN_SAFE); // closing queue
+      atomic_fetch_or (&QB->mqb_tail, MQN_SAFE); // closing queue
       return -1L; // bad luck
     }
   }
@@ -465,7 +471,7 @@ mqn_value_t mpq_pop (struct mp_queue *MQ, int flags) {
       if (is_hazard_ptr (QB, 0, 2) <= 1) {
 	free_mpq_block (QB);
       } else {
-	__sync_fetch_and_add (&mpq_blocks_wasted, 1);
+	atomic_fetch_add (&mpq_blocks_wasted, 1);
 	// ... put QB into some GC queue? ...
 	QB->mqb_magic = MQ_BLOCK_GARBAGE_MAGIC;
 	mpq_push (QB->mqb_size == MPQ_SMALL_BLOCK_SIZE ? &MqGarbageSmallBlocks : &MqGarbageBlocks, QB, flags & MPQF_RECURSIVE);
@@ -517,7 +523,7 @@ int mpq_is_empty (struct mp_queue *MQ) {
       if (is_hazard_ptr (QB, 0, 2) <= 1) {
 	free_mpq_block (QB);
       } else {
-	__sync_fetch_and_add (&mpq_blocks_wasted, 1);
+	atomic_fetch_add (&mpq_blocks_wasted, 1);
 	// ... put QB into some GC queue? ...
 	QB->mqb_magic = MQ_BLOCK_GARBAGE_MAGIC;
 	mpq_push (QB->mqb_size == MPQ_SMALL_BLOCK_SIZE ? &MqGarbageSmallBlocks : &MqGarbageBlocks, QB, 0);
@@ -558,7 +564,7 @@ long mpq_push (struct mp_queue *MQ, mqn_value_t val, int flags) {
 #define DBG(c) // fprintf (stderr, "[%d] pushing %lx to %p,%p: %c\n", mpq_this_thread_id, (long) val, MQ, QB, c);
     DBG('A');
     /*
-    if (__sync_fetch_and_add (&QB->mqb_next_allocators, 1)) {
+    if (atomic_fetch_add (&QB->mqb_next_allocators, 1)) {
       // somebody else will allocate next block; busy wait instead of spuruous alloc/free
       DBG('B')
       while (!QB->mqb_next) {
@@ -591,7 +597,7 @@ long mpq_push (struct mp_queue *MQ, mqn_value_t val, int flags) {
       DBG('F');
       NQB->mqb_magic = MQ_BLOCK_PREPARED_MAGIC;
       mpq_push (is_small ? &MqPreparedSmallBlocks : &MqPreparedBlocks, NQB, 0);
-      __sync_fetch_and_add (&mpq_blocks_prepared, 1);
+      atomic_fetch_add (&mpq_blocks_prepared, 1);
     }
   }
 #undef DBG
diff --git a/engine/engine-signals.c b/engine/engine-signals.c
index 5bba640..162202e 100644
--- a/engine/engine-signals.c
+++ b/engine/engine-signals.c
@@ -26,6 +26,7 @@
               2015-2016 Vitaliy Valtman
 */
 #include <signal.h>
+#include <stdatomic.h>
 #include <unistd.h>
 
 #include "common/kprintf.h"
@@ -42,7 +43,7 @@ void engine_set_terminal_attributes (void) {}
 /* {{{ PENDING SIGNALS */
 
 void signal_set_pending (int sig) {
-  __sync_fetch_and_or (&pending_signals, SIG2INT(sig));
+  atomic_fetch_or (&pending_signals, SIG2INT(sig));
 }
 
 int signal_check_pending (int sig) {
@@ -52,7 +53,7 @@ int signal_check_pending (int sig) {
 int signal_check_pending_and_clear (int sig) {
   int res = (pending_signals & SIG2INT(sig)) != 0;
   if (res) {
-    __sync_fetch_and_and (&pending_signals, ~SIG2INT(sig));
+    atomic_fetch_and (&pending_signals, ~SIG2INT(sig));
   }
   return res;
 }
diff --git a/net/net-connections.c b/net/net-connections.c
index a0d0553..ed5eddc 100644
--- a/net/net-connections.c
+++ b/net/net-connections.c
@@ -36,6 +36,7 @@
 #include <netinet/in.h>
 #include <netinet/tcp.h>
 #include <pthread.h>
+#include <stdatomic.h>
 #include <stddef.h>
 #include <stdio.h>
 #include <stdlib.h>
@@ -309,9 +310,9 @@ void connection_write_close (connection_job_t C) /* {{{ */ {
   if (c->status == conn_working) {
     socket_connection_job_t S = c->io_conn;
     if (S) {
-      __sync_fetch_and_or (&SOCKET_CONN_INFO(S)->flags, C_STOPREAD);
+      atomic_fetch_or (&SOCKET_CONN_INFO(S)->flags, C_STOPREAD);
     }
-    __sync_fetch_and_or (&c->flags, C_STOPREAD);
+    atomic_fetch_or (&c->flags, C_STOPREAD);
     c->status = conn_write_close;
 
     job_signal (JOB_REF_CREATE_PASS (C), JS_RUN);
@@ -354,7 +355,7 @@ int set_connection_timeout (connection_job_t C, double timeout) /* {{{ */ {
 
   if (c->flags & C_ERROR) { return 0; }
 
-  __sync_fetch_and_and (&c->flags, ~C_ALARM);
+  atomic_fetch_and (&c->flags, ~C_ALARM);
   
   if (timeout > 0) {
     job_timer_insert (C, precise_now + timeout);
@@ -382,7 +383,7 @@ int clear_connection_timeout (connection_job_t C) /* {{{ */ {
 void fail_connection (connection_job_t C, int err) /* {{{ */ {
   struct connection_info *c = CONN_INFO (C);
     
-  if (!(__sync_fetch_and_or (&c->flags, C_ERROR) & C_ERROR)) {
+  if (!(atomic_fetch_or (&c->flags, C_ERROR) & C_ERROR)) {
     c->status = conn_error;
     if (c->error >= 0) {
       c->error = err;
@@ -487,7 +488,7 @@ int cpu_server_close_connection (connection_job_t C, int who) /* {{{ */ {
 
   if (c->flags & C_ISDH) {
     MODULE_STAT->active_dh_connections --;
-    __sync_fetch_and_and (&c->flags, ~C_ISDH);
+    atomic_fetch_and (&c->flags, ~C_ISDH);
   }
 
   assert (c->io_conn);
@@ -515,7 +516,7 @@ int cpu_server_close_connection (connection_job_t C, int who) /* {{{ */ {
 
   if (c->flags & C_SPECIAL) {
     c->flags &= ~C_SPECIAL;
-    int orig_special_connections = __sync_fetch_and_add (&active_special_connections, -1);
+    int orig_special_connections = atomic_fetch_add (&active_special_connections, -1);
     if (orig_special_connections == max_special_connections) {
       int i;
       for (i = 0; i < special_listen_sockets; i++) {
@@ -541,10 +542,10 @@ int do_connection_job (job_t job, int op, struct job_thread *JT) /* {{{ */ {
     if (!(c->flags & C_ERROR)) {
       if (c->flags & C_READY_PENDING) {
         assert (c->flags & C_CONNECTED);
-        __sync_fetch_and_and (&c->flags, ~C_READY_PENDING);
+        atomic_fetch_and (&c->flags, ~C_READY_PENDING);
         MODULE_STAT->active_outbound_connections ++;        
         MODULE_STAT->active_connections ++;
-        __sync_fetch_and_add (&CONN_TARGET_INFO(c->target)->active_outbound_connections, 1);
+        atomic_fetch_add (&CONN_TARGET_INFO(c->target)->active_outbound_connections, 1);
         if (c->status == conn_connecting) {
           if (!__sync_bool_compare_and_swap (&c->status, conn_connecting, conn_working)) {
             assert (c->status == conn_error);
@@ -567,7 +568,7 @@ int do_connection_job (job_t job, int op, struct job_thread *JT) /* {{{ */ {
   }
   if (op == JS_ABORT) { // RUN IN NET-CPU THREAD
     assert (c->flags & C_ERROR);
-    if (!(__sync_fetch_and_or (&c->flags, C_FAILED) & C_FAILED)) {
+    if (!(atomic_fetch_or (&c->flags, C_FAILED) & C_FAILED)) {
       c->type->close (C, 0);
     }
     return JOB_COMPLETED;
@@ -741,7 +742,7 @@ connection_job_t alloc_new_connection (int cfd, conn_target_job_t CTJ, listening
       
       if (LC->flags & C_SPECIAL) {
         c->flags |= C_SPECIAL;
-        __sync_fetch_and_add (&active_special_connections, 1);
+        atomic_fetch_add (&active_special_connections, 1);
         
         if (active_special_connections > max_special_connections) {
           vkprintf (active_special_connections >= max_special_connections + 16 ? 0 : 1, "ERROR: forced to accept connection when special connections limit was reached (%d of %d)\n", active_special_connections, max_special_connections);
@@ -795,7 +796,7 @@ void fail_socket_connection (socket_connection_job_t C, int who) /* {{{ */ {
   struct socket_connection_info *c = SOCKET_CONN_INFO (C);
   assert (C->j_flags & JF_LOCKED);
 
-  if (!(__sync_fetch_and_or (&c->flags, C_ERROR) & C_ERROR)) {
+  if (!(atomic_fetch_or (&c->flags, C_ERROR) & C_ERROR)) {
     job_timer_remove (C);
 
     remove_event_from_heap (c->ev, 0);
@@ -864,24 +865,24 @@ int net_server_socket_reader (socket_connection_job_t C) /* {{{ */ {
 
     int p = 1;
 
-    __sync_fetch_and_or (&c->flags, C_NORD);
+    atomic_fetch_or (&c->flags, C_NORD);
     int r = readv (c->fd, tcp_recv_iovec + p, MAX_TCP_RECV_BUFFERS + 1 - p);
     MODULE_STAT->tcp_readv_calls ++;
 
     if (r <= 0) {
       if (r < 0 && errno == EAGAIN) {
       } else if (r < 0 && errno == EINTR) {
-        __sync_fetch_and_and (&c->flags, ~C_NORD);
+        atomic_fetch_and (&c->flags, ~C_NORD);
         MODULE_STAT->tcp_readv_intr ++;
         continue;
       } else {
         vkprintf (1, "Connection %d: Fatal error %m\n", c->fd);
         job_signal (JOB_REF_CREATE_PASS (C), JS_ABORT);
-        __sync_fetch_and_or (&c->flags, C_NET_FAILED);
+        atomic_fetch_or (&c->flags, C_NET_FAILED);
         return 0;
       }
     } else {
-      __sync_fetch_and_and (&c->flags, ~C_NORD);
+      atomic_fetch_and (&c->flags, ~C_NORD);
     }
       
     if (verbosity > 0 && r < 0 && errno != EAGAIN) {
@@ -959,7 +960,7 @@ int net_server_socket_writer (socket_connection_job_t C) /* {{{ */{
 
   while ((c->flags & (C_WANTWR | C_NOWR | C_ERROR | C_NET_FAILED)) == C_WANTWR) {
     if (!out->total_bytes) {
-      __sync_fetch_and_and (&c->flags, ~C_WANTWR);
+      atomic_fetch_and (&c->flags, ~C_WANTWR);
       break;
     }
 
@@ -969,7 +970,7 @@ int net_server_socket_writer (socket_connection_job_t C) /* {{{ */{
     int s = tcp_prepare_iovec (iov, &iovcnt, sizeof (iov) / sizeof (iov[0]), out);
     assert (iovcnt > 0 && s > 0);
 
-    __sync_fetch_and_or (&c->flags, C_NOWR);
+    atomic_fetch_or (&c->flags, C_NOWR);
     int r = writev (c->fd, iov, iovcnt);
     MODULE_STAT->tcp_writev_calls ++;
 
@@ -978,21 +979,21 @@ int net_server_socket_writer (socket_connection_job_t C) /* {{{ */{
         if (++c->eagain_count > 100) {
           kprintf ("Too much EAGAINs for connection %d (%s), dropping\n", c->fd, show_remote_socket_ip (C));
           job_signal (JOB_REF_CREATE_PASS (C), JS_ABORT);
-          __sync_fetch_and_or (&c->flags, C_NET_FAILED);
+          atomic_fetch_or (&c->flags, C_NET_FAILED);
           return 0;
         }
       } else if (r < 0 && errno == EINTR) {
-        __sync_fetch_and_and (&c->flags, ~C_NOWR);
+        atomic_fetch_and (&c->flags, ~C_NOWR);
         MODULE_STAT->tcp_writev_intr ++;
         continue;
       } else {
         vkprintf (1, "Connection %d: Fatal error %m\n", c->fd);
         job_signal (JOB_REF_CREATE_PASS (C), JS_ABORT);
-        __sync_fetch_and_or (&c->flags, C_NET_FAILED);
+        atomic_fetch_or (&c->flags, C_NET_FAILED);
         return 0;
       }
     } else {
-      __sync_fetch_and_and (&c->flags, ~C_NOWR);
+      atomic_fetch_and (&c->flags, ~C_NOWR);
       MODULE_STAT->tcp_writev_bytes += r;
       c->eagain_count = 0;
       t += r;
@@ -1020,7 +1021,7 @@ int net_server_socket_writer (socket_connection_job_t C) /* {{{ */{
   if (stop && !(c->flags & C_WANTWR)) {
     vkprintf (1, "Closing write_close socket\n");
     job_signal (JOB_REF_CREATE_PASS (C), JS_ABORT);
-    __sync_fetch_and_or (&c->flags, C_NET_FAILED);
+    atomic_fetch_or (&c->flags, C_NET_FAILED);
   }
 
   vkprintf (2, "socket_server_writer: written %d bytes to %d, flags=0x%08x\n", t, c->fd, c->flags);
@@ -1044,9 +1045,9 @@ int net_server_socket_read_write (socket_connection_job_t C) /* {{{ */ {
  
   if (!(c->flags & C_CONNECTED)) {
     if (!(c->flags & C_NOWR)) {
-      __sync_fetch_and_and (&c->flags, C_PERMANENT);
-      __sync_fetch_and_or (&c->flags, C_WANTRD | C_CONNECTED);
-      __sync_fetch_and_or (&CONN_INFO(c->conn)->flags, C_READY_PENDING | C_CONNECTED);
+      atomic_fetch_and (&c->flags, C_PERMANENT);
+      atomic_fetch_or (&c->flags, C_WANTRD | C_CONNECTED);
+      atomic_fetch_or (&CONN_INFO(c->conn)->flags, C_READY_PENDING | C_CONNECTED);
         
       c->type->socket_connected (C);
       job_signal (JOB_REF_CREATE_PASS (c->conn), JS_RUN);
@@ -1071,7 +1072,7 @@ int net_server_socket_read_write (socket_connection_job_t C) /* {{{ */ {
   }
 
   if (out->total_bytes) {
-    __sync_fetch_and_or (&c->flags, C_WANTWR);
+    atomic_fetch_or (&c->flags, C_WANTWR);
   }
  
   while ((c->flags & (C_NOWR | C_ERROR | C_WANTWR | C_NET_FAILED)) == C_WANTWR) {  
@@ -1110,7 +1111,7 @@ int net_server_socket_read_write_gateway (int fd, void *data, event_t *ev) /* {{
     if ((ev->state & EVT_WRITE) && (ev->ready & EVT_WRITE)) {
       clear_flags |= C_NOWR;
     }
-    __sync_fetch_and_and (&c->flags, ~clear_flags);
+    atomic_fetch_and (&c->flags, ~clear_flags);
 
     if (ev->epoll_ready & EPOLLERR) {
       int error = 0;
@@ -1344,7 +1345,7 @@ int init_listening_connection_ext (int fd, conn_type_t *type, void *extra, int m
 
   if (mode & SM_SPECIAL) {
     LC->flags |= C_SPECIAL;
-    int idx = __sync_fetch_and_add (&special_listen_sockets, 1);
+    int idx = atomic_fetch_add (&special_listen_sockets, 1);
     assert (idx < MAX_SPECIAL_LISTEN_SOCKETS);
     special_socket[idx].fd = LC->fd; 
     special_socket[idx].generation = LC->generation; 
@@ -1388,7 +1389,7 @@ int init_listening_tcpv6_connection (int fd, conn_type_t *type, void *extra, int
 void connection_event_incref (int fd, long long val) {
   struct event_descr *ev = &Events[fd];
 
-  if (!__sync_add_and_fetch (&ev->refcnt, val) && ev->data) {
+  if (!(atomic_fetch_add (&ev->refcnt, val) + val) && ev->data) {
     socket_connection_job_t C = ev->data;
     ev->data = NULL;
     job_decref (JOB_REF_PASS (C));
@@ -1400,13 +1401,13 @@ connection_job_t connection_get_by_fd (int fd) {
   if (!(int)(ev->refcnt) || !ev->data) { return NULL; }
 
   while (1) {
-    long long v = __sync_fetch_and_add (&ev->refcnt, (1ll << 32));
+    long long v = atomic_fetch_add (&ev->refcnt, (1ll << 32));
     if (((int)v) != 0) { break; }
-    v = __sync_fetch_and_add (&ev->refcnt, -(1ll << 32));
+    v = atomic_fetch_add (&ev->refcnt, -(1ll << 32));
     if (((int)v) != 0) { continue; }
     return NULL;
   }
-  __sync_fetch_and_add (&ev->refcnt, 1 - (1ll << 32));
+  atomic_fetch_add (&ev->refcnt, 1 - (1ll << 32));
   socket_connection_job_t C = job_incref (ev->data);
   
   connection_event_incref (fd, -1);
@@ -1625,7 +1626,7 @@ void destroy_dead_target_connections (conn_target_job_t CTJ) /* {{{ */ {
 
   struct tree_connection *T = CT->conn_tree;  
   if (T) {
-    __sync_fetch_and_add (&T->refcnt, 1);
+    atomic_fetch_add (&T->refcnt, 1);
   }
   
   while (1) {
@@ -1634,9 +1635,9 @@ void destroy_dead_target_connections (conn_target_job_t CTJ) /* {{{ */ {
     if (!CJ) { break; }
     
     if (connection_is_active (CONN_INFO (CJ)->flags)) {    
-      __sync_fetch_and_add (&CT->active_outbound_connections, -1);
+      atomic_fetch_add (&CT->active_outbound_connections, -1);
     }
-    __sync_fetch_and_add (&CT->outbound_connections, -1);
+    atomic_fetch_add (&CT->outbound_connections, -1);
 
     T = tree_delete_connection (T, CJ);     
   }
@@ -1707,7 +1708,7 @@ int create_new_connections (conn_target_job_t CTJ) /* {{{ */ {
   if (precise_now >= CT->next_reconnect || CT->active_outbound_connections) {
     struct tree_connection *T = CT->conn_tree;  
     if (T) {
-      __sync_fetch_and_add (&T->refcnt, 1);
+      atomic_fetch_add (&T->refcnt, 1);
     }
 
     while (CT->outbound_connections < need_c) {
@@ -1882,7 +1883,7 @@ int destroy_target (JOB_REF_ARG (CTJ)) /* {{{ */ {
   assert (CT->global_refcnt > 0);
 
   int r;
-  if (!((r = __sync_add_and_fetch (&CT->global_refcnt, -1)))) {
+  if (!((r = atomic_fetch_add (&CT->global_refcnt, -1) + -1))) {
     MODULE_STAT->active_targets--;
     MODULE_STAT->inactive_targets++;
 
@@ -1956,7 +1957,7 @@ conn_target_job_t create_target (struct conn_target_info *source, int *was_creat
     t->max_connections = source->max_connections;
     t->reconnect_timeout = source->reconnect_timeout;
 
-    if (!__sync_fetch_and_add (&t->global_refcnt, 1)) {
+    if (!atomic_fetch_add (&t->global_refcnt, 1)) {
       MODULE_STAT->active_targets++;
       MODULE_STAT->inactive_targets--;
     
@@ -2129,7 +2130,7 @@ void incr_active_dh_connections (void) {
 }
 
 int new_conn_generation (void) {
-  return __sync_fetch_and_add (&conn_generation, 1);
+  return atomic_fetch_add (&conn_generation, 1);
 }
 
 int get_cur_conn_generation (void) {
diff --git a/net/net-events.c b/net/net-events.c
index 1a14377..1925a75 100644
--- a/net/net-events.c
+++ b/net/net-events.c
@@ -32,6 +32,7 @@
 #include <netinet/tcp.h>
 #include <pwd.h>
 #include <signal.h>
+#include <stdatomic.h>
 #include <stdio.h>
 #include <stdlib.h>
 #include <string.h>
@@ -190,7 +191,7 @@ int epoll_sethandler (int fd, int prio, event_handler_t handler, void *data) {
     ev->fd = fd;
   }
   assert (!ev->refcnt);
-  __sync_fetch_and_add (&ev->refcnt, 1);
+  atomic_fetch_add (&ev->refcnt, 1);
   ev->priority = prio;
   ev->data = data;
   ev->work = handler;
diff --git a/net/net-rpc-targets.c b/net/net-rpc-targets.c
index 01d9e47..39d254b 100644
--- a/net/net-rpc-targets.c
+++ b/net/net-rpc-targets.c
@@ -23,6 +23,7 @@
 */
 
 #include <assert.h>
+#include <stdatomic.h>
 #include <stdlib.h>
 #include <string.h>
 #include <unistd.h>
@@ -92,7 +93,7 @@ static rpc_target_job_t rpc_target_alloc (struct process_id PID) {
   struct tree_rpc_target *old = rpc_target_tree;
   
   if (old) {
-    __sync_fetch_and_add (&old->refcnt, 1);
+    atomic_fetch_add (&old->refcnt, 1);
   }
 
   rpc_target_tree = tree_insert_rpc_target (rpc_target_tree, SS, lrand48_j ());
@@ -136,7 +137,7 @@ void rpc_target_insert_conn (connection_job_t C) {
   struct tree_connection *old = S->conn_tree;
 
   if (old) {
-    __sync_fetch_and_add (&old->refcnt, 1);
+    atomic_fetch_add (&old->refcnt, 1);
   }
 
   S->conn_tree = tree_insert_connection (S->conn_tree, job_incref (C), lrand48_j ());
@@ -179,7 +180,7 @@ void rpc_target_delete_conn (connection_job_t C) {
 
   struct tree_connection *old = S->conn_tree;
   if (old) {
-    __sync_fetch_and_add (&old->refcnt, 1);
+    atomic_fetch_add (&old->refcnt, 1);
   }
   S->conn_tree = tree_delete_connection (S->conn_tree, C);
   MODULE_STAT->total_connections_in_rpc_targets --;
diff --git a/vv/vv-tree.c b/vv/vv-tree.c
index d7c4987..4a4db0d 100644
--- a/vv/vv-tree.c
+++ b/vv/vv-tree.c
@@ -20,6 +20,7 @@
 
 
 #include <assert.h>
+#include <stdatomic.h>
       
 long long total_vv_tree_nodes;
 
@@ -320,7 +321,7 @@ TREE_PREFIX void SUFFIX(tree_insert_sub_,TREE_NAME) (TREE_NODE_TYPE **T, X_TYPE
     TREE_NODE_TYPE *TT = *T;
 
     if (TT) {
-      __sync_fetch_and_add (&TT->refcnt, 1);
+      atomic_fetch_add (&TT->refcnt, 1);
     }
   #endif
 
@@ -445,7 +446,7 @@ TREE_PREFIX void SUFFIX(tree_delete_sub_,TREE_NAME) (TREE_NODE_TYPE **T, X_TYPE
     TREE_NODE_TYPE *TT = *T;
 
     if (TT) {
-      __sync_fetch_and_add (&TT->refcnt, 1);
+      atomic_fetch_add (&TT->refcnt, 1);
     }
   #endif
 
@@ -578,7 +579,7 @@ TREE_PREFIX TREE_NODE_TYPE *SUFFIX (tree_alloc_, TREE_NAME) (X_TYPE x, Y_TYPE y)
   T->refcnt = 1;
   #endif
   T->left = T->right = NULL;
-  __sync_fetch_and_add (&total_vv_tree_nodes, 1);
+  atomic_fetch_add (&total_vv_tree_nodes, 1);
   return T;
 }
 
@@ -586,7 +587,7 @@ TREE_PREFIX TREE_NODE_TYPE *SUFFIX (tree_alloc_, TREE_NAME) (X_TYPE x, Y_TYPE y)
 TREE_PREFIX void SUFFIX (tree_free_, TREE_NAME) (TREE_NODE_TYPE *T) {
   #ifdef TREE_PTHREAD
     if (!T) { return; }
-    if (__sync_fetch_and_add (&T->refcnt, -1) > 1) {
+    if (atomic_fetch_add (&T->refcnt, -1) > 1) {
       return;
     }
     assert (!T->refcnt);
@@ -603,7 +604,7 @@ TREE_PREFIX void SUFFIX (tree_free_, TREE_NAME) (TREE_NODE_TYPE *T) {
   #else
     free (T);
   #endif
-  __sync_fetch_and_add (&total_vv_tree_nodes, -1);
+  atomic_fetch_add (&total_vv_tree_nodes, -1);
 }
 
 #ifdef TREE_PTHREAD
@@ -616,12 +617,12 @@ TREE_PREFIX TREE_NODE_TYPE *SUFFIX(tree_clone_, TREE_NAME) (TREE_NODE_TYPE *T) {
   assert (R);
 
   if (T->left) {
-    __sync_fetch_and_add (&T->left->refcnt, 1);
+    atomic_fetch_add (&T->left->refcnt, 1);
     R->left = T->left;
   }
   
   if (T->right) {
-    __sync_fetch_and_add (&T->right->refcnt, 1);
+    atomic_fetch_add (&T->right->refcnt, 1);
     R->right = T->right;
   }
 
@@ -646,7 +647,7 @@ TREE_PREFIX void SUFFIX(tree_relax_,TREE_NAME)  (TREE_NODE_TYPE *T) {
 
 TREE_PREFIX void SUFFIX(incref_tree_ptr_,TREE_NAME) (TREE_NODE_TYPE *T) {
   if (T) {
-    assert (__sync_fetch_and_add (&T->refcnt, 1) > 0);
+    assert (atomic_fetch_add (&T->refcnt, 1) > 0);
   }
 }
 
